<!DOCTYPE html>
<html>
  <!-- Html Head Tag-->
  <head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  <link rel="dns-prefetch" href="//cdn.bootcss.com" />
  <link rel="dns-prefetch" href="//cdn.mathjax.org" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <meta name="author" content="Jocker">
  <!-- Open Graph Data -->
  <meta property="og:title" content="YOLOv1-Translate"/>
  <meta property="og:description" content="" />
  <meta property="og:site_name" content="Jocker&#39;s"/>
  <meta property="og:type" content="article" />
  <meta property="og:image" content="http://yoursite.com"/>
  
    <link rel="alternate" href="/atom.xml" title="Jocker&#39;s" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  

  <!-- Site Title -->
  <title>Jocker's</title>

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="/css/bootstrap.min.css">
  <!-- Custom CSS -->
  
  <link rel="stylesheet" href="/css/style.light.css">

  <!-- Google Analytics --><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

  <body>
    

<!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- Page Header -->



<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

<header class="site-header header-background" style="background-image: url(/img/cover.jpg)">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="page-title with-background-image">
          <p class="title">YOLOv1-Translate</p>
          <p class="subtitle"></p>
        </div>
        <div class="site-menu with-background-image">
          <ul>
            
              <li>
                <a href="/">
                  
                  Home
                  
                </a>
              </li>
            
              <li>
                <a href="/archives">
                  
                  Archives
                  
                </a>
              </li>
            
              <li>
                <a href="https://github.com/capslockor">
                  
                  Github
                  
                </a>
              </li>
            
              <li>
                <a href="mailto:<your-email-address>">
                  
                  Email
                  
                </a>
              </li>
            
          </ul>
        </div>
      </div>
    </div>
  </div>
</header>

<article>
  <div class="container typo">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="post-info text-muted">
          
            <!-- Author -->
            <span class="author info">By Jocker</span>
          
          <!-- Date -->
          <span class="date-time info">On
            <span class="date">2018-02-25</span>
            <span class="time">08:06:55</span>
          </span>
          
          <!--  Categories  -->
            <span class="categories info">Under 

<a href="/categories/Code/">Code</a>
</span>
          
        </div>
        <!-- Tags -->
        
          <div class="post-tags text-muted">
            Tags: 

<a class="tag" href="/tags/论文/">#论文</a>


          <span id="busuanzi_container_page_pv">
                本文浏览量<span id="busuanzi_value_page_pv"></span>次
          </span>
          </div>
        
        <!-- Post Main Content -->
        <div class="post-content">
          <ul>
<li>此篇文章是对目标检测paper中的YOLOv1进行翻译，加深自己对计算机图像识别领域中的目标检测的理解，并辅助自己的一些个人理解总结。<a id="more"></a>
</li>
</ul>
<hr>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance.</p>
<p>我们提出了YOLO网络，一种全新的目标检测算法。以前在目标检测上的工作主要利用分类器来执行目标检测。相反，我们将目标检测看做一个标记目标概率的边界回归问题。<br>单个神经网络在一次评估中直接从完整图像上预测边界框和类别概率。整个检测流水线是单一神经网络，所以可以对检测性能进行端到端的优化。</p>
<p>Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork.</p>
<p>我们的统一构架非常快, 我们的基础YOLO模型可以以45f/s的速度进行图片的实时处理。Fast YOLO，一个小的yolo网络实现，可以以 155f/s 的速度处理图片，同时可以实现其他实时检测器两倍的mAP. 与最先进的检测系统相比，YOLO会出现更多的定位误差，但很少将背景预测为object。 最后YOLO会学习到目标的通用表示，当从自然图像到艺术领域泛化时，都优于其它的检测方法，包括DPM 以及 R-CNN。</p>
<hr>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Humans glance at an image and instantly know what objects are in the image, where they are, and how they interact. The human visual system is fast and accurate, allowing us to perform complex tasks like driving with little conscious thought. Fast, accurate algorithms for object detection would allow computers to drive cars without specialized sensors, enable assistive devices to convey real-time scene information to human users, and unlock the potential for general purpose, responsive robotic systems.</p>
<p>对于人类，只需要瞥一眼图像，就立即知道图像中的物体是什么，他们在哪里，和他们之间的关系是什么。人类的视觉系统是快速并且准确的，让我们能够执行复杂的任务<br>，列如驾驶时并不需要经常特意的思考。快速，准确的目标检测，可以让计算机在没有特定传感器的情况下驾驶汽车。使用辅助系统可以向人类用户传达实时的场景信息。并表现出对于一般用途和相应机器人系统的潜力。</p>
<p>Current detection systems repurpose classifiers to perform detection. To detect an object, these systems take a classifier for that object and evaluate it at various locations and scales in a test image. Systems like deformable parts models (DPM) use a sliding window approach where the classifier is run at evenly spaced locations over the entire image [10].</p>
<p>目前的目标检测系统用分类器来执行检测。为了检测目标，这些系统为该目标提供一个分类器，并且在不同的位置对其进行评估，并在测试图片中进行缩放。像DPM这样的模型，使用滑动窗口的方法，使其分类器在整个图像的均匀间隔的位置上运行。</p>
<p>More recent approaches like R-CNN use region proposal methods to first generate potential bounding boxes in an image and then run a classifier on these proposed boxes. After classification, post-processing is used to refine the bounding boxes, eliminate duplicate detections, and rescore the boxes based on other objects in the scene [13]. These complex pipelines are slow and hard to optimize because each individual component must be trained separately.</p>
<p>最近的方法，如R-CNN使用区域提出方法，首先在图像中生成潜在的边界框，然后在这些潜在边界中运行分类器。在分类器之后，处理用于细化边界框，消除重复的检测，并且根据场景中的其它目标重新定义边界框。这些复杂的流程很慢，很难优化，因为每个单独的组件都必须进行单独的训练。</p>
<p>We reframe object detection as a single regression problem, straight from image pixels to bounding box coordinates and class probabilities. Using our system, you only look once (YOLO) at an image to predict what objects are present and where they are.</p>
<p>我们将目标检测系统重新看做单一的回归问题，直接从图像像素到边界框所对应类别概率。使用我们系统，YOLO只需看一次图片，就可以标记图像中的物体和他们的类别。</p>
<p><img src="/image/1.42.32.png" alt=""></p>
<p>First, YOLO is extremely fast. Since we frame detection as a regression problem we don’t need a complex pipeline. We simply run our neural network on a new image at test time to predict detections. Our base network runs at 45 frames per second with no batch processing on a Titan X GPU and a fast version runs at more than 150 fps. This means we can process streaming video in real-time with less than 25 milliseconds of latency. Furthermore, YOLO achieves more than twice the mean average precision of other real-time systems. For a demo of our system running in real-time on a webcam please see our project webpage: <a href="http://pjreddie.com/yolo/" target="_blank" rel="noopener">http://pjreddie.com/yolo/</a>.</p>
<p>首先， yolo的速度非常的快，由于我们将检测视为回归问题，所以我们不需要复杂的流程。我们将图片输入我们的神经网络来进行测试。我们的基础网络以45f/s 的速度运行， 在Titan x gpu上没有批处理，快速版本的运行速度超过150fps， 这意味可以在不到25毫秒的延迟上处理实时媒体流视频，此外，YOLO实现了其它实时系统两倍以上的平均精度。关于我们系统在网络摄像头上实时运行的演示，请参阅我们的项目地址<a href="http://pjreddie.com/yolo/" target="_blank" rel="noopener">http://pjreddie.com/yolo/</a>.</p>
<p>Second, YOLO reasons globally about the image when making predictions. Unlike sliding window and region proposal-based techniques, YOLO sees the entire image during training and test time so it implicitly encodes contextual information about classes as well as their appearance. Fast R-CNN, a top detection method [14], mistakes background patches in an image for objects because it can’t see the larger context. YOLO makes less than half the number of background errors compared to Fast R-CNN.</p>
<p>其次， YOLO在进行预测时，会对整个图片进行全面的推理。与基于滑动窗口和区域提出的技术不同，YOLO在训练和测试期间都能看到整个图像，所以网络隐士的编码了关于类的上下文信息以及他们的外观。 Fast R-CNN是一种顶级的快速检测算法，由于它看不到更大的上下文，所以在图像中会将背景块误检测为目标。与fast R-CNN, YOLO将背景的检测错误降低了一半。</p>
<p>Third, YOLO learns generalizable representations of objects. When trained on natural images and tested on artwork, YOLO outperforms top detection methods like DPM and R-CNN by a wide margin. Since YOLO is highly generalizable it is less likely to break down when applied to new domains or unexpected inputs.</p>
<p>第三， YOLO学习目标的泛化表示，当以自然图像作为训练集并在艺术作品上进行测试时，YOLO 大幅度优于 DPM 和 R-CNN 等顶级检测算法。由于YOLO具有高度的泛化能力，因此在应用于新领域时遇到意外的输入时不容易出错。</p>
<p>YOLO still lags behind state-of-the-art detection systems in accuracy. While it can quickly identify objects in images it struggles to precisely localize some objects, especially small ones. We examine these tradeoffs further in our experiments.</p>
<p>YOLO 在精度上仍然落后于最先进的检测系统。虽然它可以快速识别图像中的目标，但它仍在努力的精确定位一些目标，尤其是小的目标。我们在实验中会进一步检查这些权衡。</p>
<p>All of our training and testing code is open source. A variety of pretrained models are also available to download.</p>
<p>所有的训练和测试代码都是开源的，各种预训练模型也都可以下载。</p>
<hr>
<h2 id="Unified-Detection"><a href="#Unified-Detection" class="headerlink" title="Unified Detection"></a>Unified Detection</h2><p>We unify the separate components of object detection into a single neural network. Our network uses features from the entire image to predict each bounding box. It also predicts all bounding boxes across all classes for an image simultaneously. This means our network reasons globally about the full image and all the objects in the image. The YOLO design enables end-to-end training and real-time speeds while maintaining high average precision.</p>
<p>我们将目标检测的单独组件集成到单个神经网络中。我们的网络使用整个图像的特征来预测每个边框。它还可以同时预测一张图像中所有类别的边界框。这意味着我们的网络可以全面推理整个图片以及图片中的的所有目标。YOLO设计可实现端到端的训练和实时速度，并且保持较高的平均精度。</p>
<p>Our system divides the input image into an $S\times S$ grid. If the center of an object falls into a grid cell, that grid cell is responsible for detecting that object.</p>
<p>我们的系统将输入图像分成 $S\times S$的网格。 如果一个目标的中心落入一个网格单元中，该网格单元负责检测该目标。</p>
<p>Each grid cell predicts $B$ bounding boxes and confidence scores for those boxes. These confidence scores reflect how confident the model is that the box contains an object and also how accurate it thinks the box is that it predicts. Formally we define confidence as $\Pr(\textrm{Object}) * \textrm{IOU}_{\textrm{pred}}^{\textrm{truth}}$. If no object exists in that cell, the confidence scores should be zero. Otherwise we want the confidence score to equal the intersection over union (IOU) between the predicted box and the ground truth.</p>
<p>每个网格单元预测这些盒子的 $B$ 个边界框和置信度分数。 这些置信度分数反应了该模型对盒子是否包含某种目标，以及它预测的盒子的准确程度的信心。在形式上，我们将置信度定义为 $\Pr(\textrm{Object}) * \textrm{IOU}_{\textrm{pred}}^{\textrm{truth}}$。 如果该单元格中不存在目标，则置信度分数应为零。否则我们希望置信分数等于预测框与真实值之间联合部分的交集（IOU）。</p>
<p>Each bounding box consists of 5 predictions: $x$, $y$, $w$, $h$, and confidence. The $(x,y)$ coordinates represent the center of the box relative to the bounds of the grid cell. The width and height are predicted relative to the whole image. Finally the confidence prediction represents the IOU between the predicted box and any ground truth box.</p>
<p>每个边界框包含5个预测， $x$, $y$, $w$, $h$ 和 置信度。 $(x, y)$ 坐标表示边界框相对于网格单元边界框的中心，宽度和高度是相对于整张图预测的。最后置信度预测表示预测框与实际边界框的IOU。</p>
<p>Each grid cell also predicts $C$ conditional class probabilities, $\Pr(\textrm{Class}_i | \textrm{Object})$. These probabilities are conditioned on the grid cell containing an object. We only predict one set of class probabilities per grid cell, regardless of the number of boxes $B$.</p>
<p>每个网格单元还预测 $C$ 个类别条件概率， $\Pr(\textrm{Class}_i | \textrm{Object})$. 这些概率以包含目标的网络单元格为条件。每个网格我们只预测的一组类别概率，二不管边界框的数量 $B$ 是多少。</p>
<p>At test time we multiply the conditional class probabilities and the individual box confidence predictions。</p>
<p>它为我们提供了每个框特定类别的置信度分数。这些分数编码了该类出现在框中的概率以及预测框拟合目标的程度。</p>
<p><img src="/image/2.34.42.png" alt=""></p>
<p>For evaluating YOLO on Pascal VOC, we use $S=7$, $B=2$. Pascal VOC has 20 labelled classes so $C=20$. Our final prediction is a $7\times 7 \times 30$ tensor.</p>
<p>在Pascal VOC 上评估 YOLO网络， 我们使用了 $S = 7$, $B = 2$。 Pascal VOC 有 20 个标注类， 所以我们的最终预测是 $7 \times 7 \times 30$ 的张量。</p>
<hr>

        </div>
        <div id="gitmentContainer"></div>
        <link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
        <script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
        <script>
        var gitment = new Gitment({
            owner: 'capslockor',
            repo: 'capslockor.github.io',
            oauth: {
                client_id: 'f15b4fe423822d061f94',
                client_secret: 'c6314e1933de04aeb41bc3da160fd1a78c0e774d',
            },
        });
        gitment.render('gitmentContainer');
        </script>
      </div>
    </div>
  </div>
</article>



    <!-- Footer -->
<footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <p class="copyright text-muted">
          Theme By <a target="_blank" href="https://github.com/levblanc">Levblanc.</a>
          Inspired By <a target="_blank" href="https://github.com/klugjo/hexo-theme-clean-blog">Clean Blog.</a>
        <p class="copyright text-muted">
          Powered By <a target="_blank" href="https://hexo.io/">Hexo.</a>
          <span id="busuanzi_container_site_pv">
            本站总访问量	<span id="busuanzi_value_site_pv"></span>次
          </span>
        </p>
      </div>
    </div>
  </div>
</footer>


    <!-- After Footer Scripts -->
<script src="/js/highlight.pack.js"></script>
<script>
  document.addEventListener("DOMContentLoaded", function(event) {
    var codeBlocks = Array.prototype.slice.call(document.getElementsByTagName('pre'))
    codeBlocks.forEach(function(block, index) {
      hljs.highlightBlock(block);
    });
  });
</script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]]}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>

